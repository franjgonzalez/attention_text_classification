# Global parameters
model_dir: ckpt/
data_dir: tmp/
pred_dir: pred/
# Embedding parameters
embedding_size: 50
vocab_size: 20000
# Model parameters
hidden_size: 128
attention_size: 50
# Optimizer parameters
learning_rate: 0.0001
batch_size: 1024
train:
  steps: 150000
eval:
  steps: 1000
  start_delay_secs: 60
  throttle_secs: 800
